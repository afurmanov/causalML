---
title: "alex-hw1-html.rmd"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(bnlearn)
```

## Question 1: Building a DAG (5 points)


### 1.1
Write out the factorization of the joint distribution implied by the DAG using mathematical notation. (1 point)

$P(A, E, S, O, R, T) == P(A)P(S)P(E|A,S)P(O|E)P(R|E)P(T|O,R)$

### 1.2 
Rewrite the above factorization in *bnlearn*'s string representation. (1 point)
```{r dagStr}
dagStr <- "[A][S][E|A:S][O|E][R|E][T|O:R]"
```


### 1.3
Use this to create a DAG in *bnlearn*. (1 point)

```{r dag}
dag <- model2network(dagStr)
```

### 1.4
Print the class of the DAG object. (1 point)
```{r class}
class(dag)
```

### 1.5
Use `graphviz.plot` to plot the DAG. (1 point)

```{r graphviz}
graphviz.plot(dag)
```


## Question 2: Experimenting with graph utilities (5 points)

### 2.1
Extract and print the nodes and arcs of the DAG you created in previous questions. (1 point)
```{r nodes}
nodes(dag)
arcs(dag)
```

### 2.2
Extract and print the parents and the children of each node using `parents` and `children` functions. (1 point)
```{r parents}
for(n in nodes(dag)) {
  cat(n, "'s parents are: '", parents(dag,n), "'.  ")
  cat(n, "'s children are: '", children(dag,n), "'")
  cat("\n")
}
```

### 2.3
Use the `mb` function to extract the Markov blanket of A, E, and T. (1 point)

```{r mb}
mb(dag, "A")
mb(dag, "E")
mb(dag, "T")
```

### 2.4
How do you identify the Markov blanket from the DAG? (1 point)
For node N Markov blanked is identified as its parents, its children and parents of those children, or
in R code:
(?) Should it be expressed in code?

### 2.5
Describe, in terms of coniditional independence (NOT in terms of the DAG) the definition of a Markov blanket. (1 point)

If M = Markov Blanket of variable Y from set of random variables S then Y when conditioned on M is indpendent on any subset X of set S provided
$X \bigcap M=\emptyset$

## Question 3: Conditional probability distribution (CPD) parameter estimation (5 points)

Bayesian network = DAG + CPD with specified parameters

### 3.1
Fit the parameters of the DAG from the data stored in survey2.txt using Bayesian estimation, and save the result into an object of class bn.fit. (2 points)
```{r bn.fit}
survey <- read.table("/Users/alex/i/causalML/HW/hw1_release/survey2.txt", header = TRUE)
survey[] <- lapply(survey, function(x) as.factor(x))
bn.bayesDefault <- bn.fit(dag, data = survey, method = "bayes")
```

### 3.2
Play with the Bayesian prior parameter **iss** and report the changes in the parameters learned from Bayesian network. Explain the changes. (3 points)
```{r bayes-iss}
sink("bn.bayes_iss_default")
bn.fit(dag, data = survey, method = "bayes")
sink()

sink("bn.bayes_iss_1")
bn.fit(dag, data = survey, method = "bayes", iss=1)
sink()

sink("bn.bayes_iss_5")
bn.fit(dag, data = survey, method = "bayes", iss=5)
sink()

sink("bn.bayes_iss_10")
bn.fit(dag, data = survey, method = "bayes", iss=10)
sink()

sink("bn.bayes_iss_100")
bn.fit(dag, data = survey, method = "bayes", iss=100)
sink()

sink("bn.bayes_iss_1000")
bn.fit(dag, data = survey, method = "bayes", iss=1000)
sink()

sink("bn.bayes_iss_1000000")
bn.fit(dag, data = survey, method = "bayes", iss=1000000)
sink()
```

Explanation of differences in conditional propabilities for various `iss` argument:

Since `iss` represents sample size of imaginary prior distribution, which is uniform distribution,
the large value for `iss` we use the closer conditional probabilities become to uniform distribution.
It is especially demonstrated by latest example (iss=1000000), where calculated probabilities are very very close
to uniform distribution. Also, when `iss` <= 10, calculated conditionl probabilities are almost
identical, which means prior distribution does not play any significant role and since assigning
prior distribution to uniform is an actually a very wild guess, it means smaller `iss` values are is
what should be used in order to get "right" values of conditional probabilities (i.e. where effect of inital
prior is eliminated)

### 5.1
Compute and plot the PDAG of the DAG for the survey data using the `cpdag` function.  Call this PDAG P1 and the original DAG D1.  How does P1 and D1 compare?  Explain any similarities or differences. (1 point)

```{r cpdag}
d1 <- dag
p1 <- cpdag(d1)
graphviz.plot(p1)
```
Explanation of result: p1 is identical to d1 because any arrow reversal in p1 would change set of open V-structures:
i.e. reversing O->E would create new open V structure: O->E<-A which cannot be found in d1

### 5.2 Create a DAG D2 that is the same as D1 except that it has a new arc from Occupation to Residence. This makes sense because surely somebody's
job determines where they live (or is it the other way around?).  Note
that this is a fine example of applying domain knowledge about the
data generative process in causal model development. Plot the result
with `graphviz.plot`. Now recompute a PDAG P2 from D2.  What, if
anything, is different between P1 and P2 and what explains these
differences or lack of differences? (1 point)

```{r dag2}
d2 <- model2network("[A][S][E|A:S][O|E][R|E:O][T|O:R]")
graphviz.plot(d2)
p2 <- cpdag(d2)
graphviz.plot(p2)
```

p1 is different than p2 and differences are:
                                            
  - skeletal difference, p2 has an extra edge R - O                                            
  - Edge R-O has no direction, which meas whatever direction is assigned to it, set of open
     V-structures remain the same.

### 5.3 Create a third DAG D3 that is different from the second DAG
(with the O->R edge) but is in the same Markov equivalence class. Do
this by reasoning about P2 -- in other words look at P2 and create
another DAG D3, such that `cpdag(D3)` will also produce P2. Plot
D3. (1 point)

```{r dag3}
d3 <- model2network("[A][S][E|A:S][O|E:R][R|E][T|O:R]")
graphviz.plot(d3)
```

d3 could be built by assigning different than in d2 direction between
O and R (i.e. R->O) , because it is a node in p2 not having any
direction (i.e. reversible)

### 5.4
Calculate the log-likelihood of the data given D2 and the
log-likelihood of the data given D3.  These values should be the same,
explain why.  You can use the `score` function with the argument
`type = 'loglik`, or you can simply se the `logLik` function, which is
just a wrapper for `score`.  You dont need to provide paramter values
for the CPDs of the DAG, `score` will estimate them for you. (1 point)

```{r score}
score(d2, survey, type="loglik")
score(d3, survey, type="loglik")
```

Calculated scores are same because conditional indpendencies extracted
from data ("survey2.txt") could be equally described by both graphs -
d2 and d3.

## Question 6: Modeling and Inference using Pyro (18 points)

If you are new to tensor-based frameworks, make sure you give yourself
plenty of time for this question.  It takes time to get used to
debugging.  One common source of bugs is integers, *pyro* prefers you
use floats (e.g., `torch.tensor(1.0)` instead of `torch.tensor(1)`).
If you hit a bug and solve it, why not share with your classmates on
Piazza?
    
### 6.1 Modeling 

Use *pyro* to reimplement the Bayesian network with parameter values
you fitted in question 3. Use default *iss* values and round parameter
estimates to 2 decimal places. When coding conditional probability
table using tensor, make sure its meaning is clear for the purpose of
easy debugging and readability. You can use comments or alias as shown
here. In this example, it is clear that `P('on')=0.8, and P('off')=0.2`.


```
X_alias = ['off', 'on']
prob_X = tensor([0.2, 0.8])
```


When there are multiple variables conditioned on, make sure the order
they are coded match the order they are sampled in the model. For
example, assuming $Z \in \{z1, z2\}$ is conditioned on $X \in \{x1,
x2, x3\}$ and $Y \in \{y1, y2\}$, the Conditional Probability Table
(CPT) of Z can be coded in two ways ($a$ and $b$ here), each
corresponds to a different order of the dimensions when generating
sample of Z using pyro.sample. It is suggested that you write comments
on what probability it is (e.g.P(Z=z1|X=x1,Y=y1)) for each entry in
the CPT. (6 points)

```
prob_X = tensor([P(X=x1), P(X=x2)])
prob_Y = tensor([P(Y=y1), P(Y=y2)])

a.
prob_Z = tensor([[[P(Z=z1|X=x1,Y=y1), P(Z=z2|X=x1,Y=y1)],
                  [P(Z=z1|X=x1,Y=y2), P(Z=z2|X=x1,Y=y2)]],
                  
                  [P(Z=z1|X=x2,Y=y1), P(Z=z2|X=x2,Y=y1)],
                  [P(Z=z1|X=x2,Y=y2), P(Z=z2|X=x2,Y=y2)]],
                  
                  [P(Z=z1|X=x3,Y=y1), P(Z=z2|X=x3,Y=y1)],
                  [P(Z=z1|X=x3,Y=y2), P(Z=z2|X=x3,Y=y2)]]])

X = pyro.sample("Z", dist.Categorical(probs=prob_X))      
Y = pyro.sample("Z", dist.Categorical(probs=prob_Y))  
Z = pyro.sample("Z", dist.Categorical(probs=prob_Z[X][Y]))
                  
b.             
prob_Z = tensor([[[P(Z=z1|X=x1,Y=y1), P(Z=z2|X=x1,Y=y1)],
                  [P(Z=z1|X=x2,Y=y1), P(Z=z2|X=x2,Y=y1)],
                  [P(Z=z1|X=x3,Y=y1), P(Z=z2|X=x3,Y=y1)]],
                  
                  [P(Z=z1|X=x1,Y=y2), P(Z=z2|X=x1,Y=y2)],
                  [P(Z=z1|X=x2,Y=y2), P(Z=z2|X=x2,Y=y2)],
                  [P(Z=z1|X=x3,Y=y2), P(Z=z2|X=x3,Y=y2)]]])

X = pyro.sample("Z", dist.Categorical(probs=prob_X))      
Y = pyro.sample("Z", dist.Categorical(probs=prob_Y)) 
Z = pyro.sample("Z", dist.Categorical(probs=prob_Z[Y][X]))         
```


### 6.2 Inference

There are two broad categories of causal inference questions, one is to predict effects from causes, referred to as forward causal inference, and the other is to predict causes from effects, referred to as reverse causal inference. Forward causal inference is straightforward to do through forward sampling, without the need of any inference algorithm. Forward sampling doesn't work for reverse causal inference, since there is no guarantee the sample generated matches the evidence we observed. An easy solution is rejection sampling, which rejects all the samples that do not match the evidence. But it can be very inefficient when the probability of the observed evidence is very small. An improvement is likelihood weighting, a special case of importance sampling, which samples unobserved variables like in forward sampling, but sets the observed variables to the same value as evidence, and weights each sample by its likelihood. An caveat of importance sampling is its accuracy depends on how close the proposal distribution is to the target distribution. In the case of Bayesian network, the proposal distribution is often the CPTs, and the target distribution is the posterior distribution we want to estimate. (For details of the theory of different sampling methods, see "Probabilistic Graphical Models" Chapter 12)

Pyro has implemented many inference algorithms including importance sampling, and we encourage you to experiment with them. Detailed understanding about how these methods work in Pyro is not a requirement. For the purpose of the homework, it's sufficient to have a high level understanding of the general idea and be able to use at least one of the inference algorithms in Pyro in your model. 

Most of the inference algorithms implemented in Pyro are approximate inference algorithms either through sampling or variational inference. Exact inference using variable elimination is NP hard. It becomes intractable when the model is large. However, most models in homeworks are fairly small. Although inference can be done manually without much efforts in small networks, inference using Pyro is required in this question.

#### 6.2.a

Implement forward causal inference using `pyro.condition`. Assuming you observed a person with a university degree. What is your prediction of this person's means of travel? Provide a histogram of the marginal distribution on the variable "T". (6 points)


#### 6.2.b

Implement reverse causal inference using `pyro.condition` and an inference algorithm in Pyro. Assuming you observed a self-employed person who lives in a big city. What is your prediction of this person's age?  Provide a histogram of the marginal on the variable "A". (6 points)
    
