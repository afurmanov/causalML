---
title: "alex-hw1-html.rmd"
output:
  pdf_document: default
  html_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(bnlearn)
```

## Question 1: Building a DAG (5 points)


### 1.1
Write out the factorization of the joint distribution implied by the DAG using mathematical notation. (1 point)

$P(A, E, S, O, R, T) == P(A)P(S)P(E|A,S)P(O|E)P(R|E)P(T|O,R)$

### 1.2 
Rewrite the above factorization in *bnlearn*'s string representation. (1 point)
```{r dagStr}
dagStr <- "[A][S][E|A:S][O|E][R|E][T|O:R]"
```


### 1.3
Use this to create a DAG in *bnlearn*. (1 point)

```{r dag}
dag <- model2network(dagStr)
```

### 1.4
Print the class of the DAG object. (1 point)
```{r class}
class(dag)
```

### 1.5
Use `graphviz.plot` to plot the DAG. (1 point)

```{r graphviz}
graphviz.plot(dag)
```


## Question 2: Experimenting with graph utilities (5 points)

### 2.1
Extract and print the nodes and arcs of the DAG you created in previous questions. (1 point)
```{r nodes}
nodes(dag)
arcs(dag)
```

### 2.2
Extract and print the parents and the children of each node using `parents` and `children` functions. (1 point)
```{r parents}
for(n in nodes(dag)) {
  cat(n, "'s parents are: '", parents(dag,n), "'.  ")
  cat(n, "'s children are: '", children(dag,n), "'")
  cat("\n")
}
```

### 2.3
Use the `mb` function to extract the Markov blanket of A, E, and T. (1 point)

```{r mb}
mb(dag, "A")
mb(dag, "E")
mb(dag, "T")
```

### 2.4
How do you identify the Markov blanket from the DAG? (1 point)
For node N Markov blanked is identified as its parents, its children and parents of those children, or
in R code:
(?) Should it be expressed in code?

### 2.5
Describe, in terms of coniditional independence (NOT in terms of the DAG) the definition of a Markov blanket. (1 point)

If M = Markov Blanket of variable Y from set of random variables S then Y when conditioned on M is indpendent on any subset X of set S provided
$X \bigcap M=\emptyset$

## Question 3: Conditional probability distribution (CPD) parameter estimation (5 points)

Bayesian network = DAG + CPD with specified parameters

### 3.1
Fit the parameters of the DAG from the data stored in survey2.txt using Bayesian estimation, and save the result into an object of class bn.fit. (2 points)
```{r bn.fit}
survey <- read.table("/Users/alex/i/causalML/HW/hw1_release/survey2.txt", header = TRUE)
survey[] <- lapply(survey, function(x) as.factor(x))
bn.bayesDefault <- bn.fit(dag, data = survey, method = "bayes")
```

### 3.2
Play with the Bayesian prior parameter **iss** and report the changes in the parameters learned from Bayesian network. Explain the changes. (3 points)
```{r bayes-iss}
sink("bn.bayes_iss_default")
bn.fit(dag, data = survey, method = "bayes")
sink()

sink("bn.bayes_iss_1")
bn.fit(dag, data = survey, method = "bayes", iss=1)
sink()

sink("bn.bayes_iss_5")
bn.fit(dag, data = survey, method = "bayes", iss=5)
sink()

sink("bn.bayes_iss_10")
bn.fit(dag, data = survey, method = "bayes", iss=10)
sink()

sink("bn.bayes_iss_100")
bn.fit(dag, data = survey, method = "bayes", iss=100)
sink()

sink("bn.bayes_iss_1000")
bn.fit(dag, data = survey, method = "bayes", iss=1000)
sink()

sink("bn.bayes_iss_1000000")
bn.fit(dag, data = survey, method = "bayes", iss=1000000)
sink()
```

Explanation of differences in conditional propabilities for various `iss` argument:

Since `iss` represents sample size of imaginary prior distribution, which is uniform distribution,
the large value for `iss` we use the closer conditional probabilities become to uniform distribution.
It is especially demonstrated by latest example (iss=1000000), where calculated probabilities are very very close
to uniform distribution. Also, when `iss` <= 10, calculated conditionl probabilities are almost
identical, which means prior distribution does not play any significant role and since assigning
prior distribution to uniform is an actually a very wild guess, it means smaller `iss` values are is
what should be used in order to get "right" values of conditional probabilities (i.e. where effect of inital
prior is eliminated)

### 5.1
Compute and plot the PDAG of the DAG for the survey data using the `cpdag` function.  Call this PDAG P1 and the original DAG D1.  How does P1 and D1 compare?  Explain any similarities or differences. (1 point)

```{r cpdag}
d1 <- dag
p1 <- cpdag(d1)
graphviz.plot(p1)
```
Explanation of result: p1 is identical to d1 because any arrow reversal in p1 would change set of open V-structures:
i.e. reversing O->E would create new open V structure: O->E<-A which cannot be found in d1

### 5.2 Create a DAG D2 that is the same as D1 except that it has a new arc from Occupation to Residence. This makes sense because surely somebody's
job determines where they live (or is it the other way around?).  Note
that this is a fine example of applying domain knowledge about the
data generative process in causal model development. Plot the result
with `graphviz.plot`. Now recompute a PDAG P2 from D2.  What, if
anything, is different between P1 and P2 and what explains these
differences or lack of differences? (1 point)

```{r dag2}
d2 <- model2network("[A][S][E|A:S][O|E][R|E:O][T|O:R]")
graphviz.plot(d2)
p2 <- cpdag(d2)
graphviz.plot(p2)
```

p1 is different than p2 and differences are:
                                            
  - skeletal difference, p2 has an extra edge R - O                                            
  - Edge R-O has no direction, which meas whatever direction is assigned to it, set of open
     V-structures remain the same.

### 5.3 Create a third DAG D3 that is different from the second DAG
(with the O->R edge) but is in the same Markov equivalence class. Do
this by reasoning about P2 -- in other words look at P2 and create
another DAG D3, such that `cpdag(D3)` will also produce P2. Plot
D3. (1 point)

```{r dag3}
d3 <- model2network("[A][S][E|A:S][O|E:R][R|E][T|O:R]")
graphviz.plot(d3)
```

d3 could be built by assigning different than in d2 direction between
O and R (i.e. R->O) , because it is a node in p2 not having any
direction (i.e. reversible)

### 5.4
Calculate the log-likelihood of the data given D2 and the
log-likelihood of the data given D3.  These values should be the same,
explain why.  You can use the `score` function with the argument
`type = 'loglik`, or you can simply se the `logLik` function, which is
just a wrapper for `score`.  You dont need to provide paramter values
for the CPDs of the DAG, `score` will estimate them for you. (1 point)

```{r score}
score(d2, survey, type="loglik")
score(d3, survey, type="loglik")
```

Calculated scores are same because conditional indpendencies extracted
from data ("survey2.txt") could be equally described by both graphs -
d2 and d3.

## Question 6: Modeling and Inference using Pyro (18 points)

If you are new to tensor-based frameworks, make sure you give yourself
plenty of time for this question.  It takes time to get used to
debugging.  One common source of bugs is integers, *pyro* prefers you
use floats (e.g., `torch.tensor(1.0)` instead of `torch.tensor(1)`).
If you hit a bug and solve it, why not share with your classmates on
Piazza?
    
### 6.1 Modeling

```{python model}
import torch
import pyro
from pyro.distributions import Categorical
import torch
from collections import Counter

pyro.set_rng_seed(101)

prob_A = torch.tensor([0.36, 0.16, 0.48]) # A=adult, A=old, A=young

prob_S = torch.tensor([0.55, 0.45]) #S=F, S=M

prob_E = torch.tensor([
    [[0.64, 0.36], #E=high|S=F,A=adult, E=uni|S=F,A=adult
    [0.84, 0.16],  #E=high|S=F,A=old,   E=uni|S=F,A=old
    [0.16, 0.84]], #E=high|S=F,A=young, E=uni|S=F,A=young

    [[0.72, 0.28], #E=high|S=M,A=adult, E=uni|S=M,A=adult
    [0.89, 0.11],  #E=high|S=M,A=old,   E=uni|S=M,A=old
    [0.81, 0.19]], #E=high|S=M,A=young, E=uni|S=M,A=young
    ])

prob_O = torch.tensor([
    [0.98, 0.02], #O=emp|E=high,  O=self|E=high
    [0.97, 0.03]  #O=emp|E=uni,   O=self|E=uni
    ])


prob_R = torch.tensor([
    [0.72, 0.28], #R=big|E=high, R=small|E=high
    [0.94, 0.06]  #R=big|E=uni,  R=small|E=uni
    ])

prob_T = torch.tensor([
    [[0.71, 0.14, 0.15], #T=car|R=big,O=emp, T=other|R=big,O=emp, T=train|R=big,O=emp
    [0.68, 0.16, 0.16]], #T=car|R=big,O=self, T=other|R=big,O=self, T=train|R=big,O=self

    [[0.55, 0.08, 0.37], #T=car|R=small,O=emp, T=other|R=small,O=emp, T=train|R=small,O=emp
    [0.73, 0.25, 0.02]], #T=car|R=small,O=self, T=other|R=small,O=self, T=train|R=small,O=self
    ])

def transportation():
    S=pyro.sample("S", Categorical(probs=prob_S))
    A=pyro.sample("A", Categorical(probs=prob_A))
    E=pyro.sample("E", Categorical(probs=prob_E[S][A]))
    O=pyro.sample("O", Categorical(probs=prob_O[E]))
    R=pyro.sample("R", Categorical(probs=prob_R[E]))
    T=pyro.sample("T", Categorical(probs=prob_T[R][O]))
    return A, R, E, O, S, T
```

# 6.2.a Forward casual inference

```{python forward_sampling}
samples_total = 10000
condtioned_on_E_uni = pyro.condition(transportation, data={"E": torch.tensor(1)})
samples_cond = [int(condtioned_on_E_uni()[5]) for i in range (samples_total)]

histogram_cond = Counter(samples_cond)
for key in histogram_cond:
    histogram_cond[key] /= samples_total

print(f"""marginal distribution of T given E=uni:
(i.e. means of travel, where Car: 0, Other: 1, Train:2)
{histogram_cond}""")
```


